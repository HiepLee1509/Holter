import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow.keras.models import load_model
from scipy.signal import find_peaks # PhÃ¡t hiá»‡n Ä‘á»‰nh R
import pywt # ThÆ° viá»‡n Wavelet
# --- Cáº¤U HÃŒNH Dá»® LIá»†U & Lá»œI KHUYÃŠN ---

# Äá»‹nh nghÄ©a thÃ´ng tin chi tiáº¿t cho 5 lá»›p (Classes)
CLASS_INFO = {
    'N': {
        "name": "BÃ¬nh thÆ°á»ng (Normal)",
        "color": "green",
        "advice": "Nhá»‹p tim cá»§a báº¡n Ä‘ang á»Ÿ tráº¡ng thÃ¡i á»•n Ä‘á»‹nh. HÃ£y duy trÃ¬ lá»‘i sá»‘ng lÃ nh máº¡nh, táº­p thá»ƒ dá»¥c Ä‘á»u Ä‘áº·n vÃ  Äƒn uá»‘ng cÃ¢n báº±ng."
    },
    'S': {
        "name": "Ngoáº¡i tÃ¢m thu trÃªn tháº¥t (SVEB)",
        "color": "orange",
        "advice": "ThÆ°á»ng lÃ nh tÃ­nh nhÆ°ng cÃ³ thá»ƒ do cÄƒng tháº³ng, caffeine hoáº·c thiáº¿u ngá»§. NÃªn háº¡n cháº¿ cháº¥t kÃ­ch thÃ­ch, nghá»‰ ngÆ¡i há»£p lÃ½. Náº¿u tháº¥y há»“i há»™p nhiá»u, hÃ£y Ä‘i khÃ¡m."
    },
    'V': {
        "name": "Ngoáº¡i tÃ¢m thu tháº¥t (VEB)",
        "color": "red",
        "advice": "CÃ³ thá»ƒ gÃ¢y cáº£m giÃ¡c háº«ng nhá»‹p. NguyÃªn nhÃ¢n cÃ³ thá»ƒ do rá»‘i loáº¡n Ä‘iá»‡n giáº£i, bá»‡nh tim ná»n hoáº·c stress. Cáº§n theo dÃµi táº§n suáº¥t, náº¿u xuáº¥t hiá»‡n dÃ y Ä‘áº·c hoáº·c gÃ¢y chÃ³ng máº·t, cáº§n gáº·p bÃ¡c sÄ© tim máº¡ch ngay."
    },
    'F': {
        "name": "Nhá»‹p há»—n há»£p (Fusion Beat)",
        "color": "purple",
        "advice": "LÃ  sá»± káº¿t há»£p giá»¯a nhá»‹p bÃ¬nh thÆ°á»ng vÃ  nhá»‹p báº¥t thÆ°á»ng. ÄÃ¢y lÃ  dáº¥u hiá»‡u cáº§n Ä‘Æ°á»£c bÃ¡c sÄ© chuyÃªn khoa Ä‘Ã¡nh giÃ¡ ká»¹ hÆ¡n qua Holter ECG."
    },
    'Q': {
        "name": "Nhá»‹p khÃ´ng xÃ¡c Ä‘á»‹nh (Unknown)",
        "color": "gray",
        "advice": "TÃ­n hiá»‡u bá»‹ nhiá»…u hoáº·c khÃ´ng rÃµ rÃ ng. Vui lÃ²ng kiá»ƒm tra láº¡i thiáº¿t bá»‹ Ä‘o, tiáº¿p xÃºc Ä‘iá»‡n cá»±c vÃ  Ä‘o láº¡i trong tráº¡ng thÃ¡i tÄ©nh. Hoáº·c Ä‘i khÃ¡m chuyÃªn khoa Ä‘á»ƒ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ chÃ­nh xÃ¡c hÆ¡n."
    }
}

CLASSES_KEYS = ['N', 'S', 'V', 'F', 'Q']

def load_arrhythmia_model(model_path="model\\ecg_model_code 17_t5.h5"):
    try:
        model = load_model(model_path, compile=False)
        return model
    except Exception as e:
        print(f"Lá»—i táº£i model: {e}")
        return None

def get_model_input_length(model):
    """Tá»± Ä‘á»™ng láº¥y Ä‘á»™ dÃ i input Ä‘áº§u vÃ o cá»§a model"""
    try:
        input_shape = model.input_shape
        if input_shape and len(input_shape) >= 2 and input_shape[1] is not None:
            return int(input_shape[1])      #input_shape = (None, 187, 1) = (batch_size, input_length, features)
        # Náº¿u khÃ´ng láº¥y Ä‘Æ°á»£c tá»« input_shape, thá»­ láº¥y tá»« lá»›p Ä‘áº§u tiÃªn
        first_layer = model.layers[0]
        if hasattr(first_layer, 'input_shape'):
            cfg_shape = first_layer.input_shape
            if cfg_shape and len(cfg_shape) >= 2 and cfg_shape[1] is not None:
                 return int(cfg_shape[1])
    except:
        pass
    return 187 # Fallback

def denoise_signal_wavelet(signal, wavelet='sym8', level=1):
    """Lá»c nhiá»…u Wavelet"""
    if len(signal) < 10:
        return signal
    try:
        coeffs = pywt.wavedec(signal, wavelet, mode='per', level=level) 
        detail_coeffs = coeffs[-1]
        sigma = np.median(np.abs(detail_coeffs)) / 0.6745 
        thresh = sigma * np.sqrt(2 * np.log(len(signal)))
        new_coeffs = [coeffs[0]]
        for c in coeffs[1:]:
            new_coeffs.append(pywt.threshold(c, thresh, mode='soft'))
        denoised_signal = pywt.waverec(new_coeffs, wavelet, mode='per')
        
        if len(denoised_signal) > len(signal):
            denoised_signal = denoised_signal[:len(signal)]
        elif len(denoised_signal) < len(signal):
            pad_width = len(signal) - len(denoised_signal)
            denoised_signal = np.pad(denoised_signal, (0, pad_width), 'edge')
        return denoised_signal
    except:
        return signal

def detect_and_segment(denoised_ecg_signal, r_peak_height=0.5, r_peak_distance=150, output_length=187):
    """PhÃ¡t hiá»‡n Ä‘á»‰nh R vÃ  phÃ¢n Ä‘oáº¡n"""
    peaks, _ = find_peaks(denoised_ecg_signal, height=r_peak_height, distance=r_peak_distance)
    
    ratio_before = 99 / 187
    window_before = int(output_length * ratio_before)
    window_after = output_length - window_before - 1
    
    segments = []
    valid_peak_locations = []
    
    for peak_loc in peaks:
        start = peak_loc - window_before
        end = peak_loc + window_after + 1
        if start < 0 or end > len(denoised_ecg_signal):
            continue
        segment = denoised_ecg_signal[start : end]
        if len(segment) == output_length:
            segments.append(segment)
            valid_peak_locations.append(peak_loc)
        
    if not segments:
        return np.array([]), np.array([])
        
    return np.array(segments), np.array(valid_peak_locations)

def predict_from_segments(segments_array, model):
    """Dá»± Ä‘oÃ¡n vÃ  tráº£ vá» mÃ£ lá»›p (N, S, V...)"""
    if segments_array.ndim == 2:
        X = segments_array.reshape(-1, segments_array.shape[1], 1)  # ThÃªm chiá»u features=1
    else:
        X = segments_array

    y_pred_probs = model.predict(X)
    y_pred_indices = np.argmax(y_pred_probs, axis=1)
    
    # Tráº£ vá» mÃ£ kÃ½ tá»± (N, S, V...) Ä‘á»ƒ frontend tra cá»©u trong CLASS_INFO
    predicted_codes = [CLASSES_KEYS[i] for i in y_pred_indices]
    return predicted_codes, y_pred_indices

def calculate_hrv_metrics(peaks, fs=360):
    """
    TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ biáº¿n thiÃªn nhá»‹p tim (HRV) cÆ¡ báº£n.
    Input:
        peaks: máº£ng chá»©a vá»‹ trÃ­ (index) cÃ¡c Ä‘á»‰nh R
        fs: táº§n sá»‘ láº¥y máº«u
    Output:
        dict chá»©a cÃ¡c chá»‰ sá»‘ vÃ  dá»¯ liá»‡u váº½ biá»ƒu Ä‘á»“
    """
    if len(peaks) < 2:
        return None
    
    # 1. TÃ­nh khoáº£ng cÃ¡ch RR (RR intervals) ra Ä‘Æ¡n vá»‹ mili-giÃ¢y (ms)
    # np.diff(peaks) lÃ  khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘á»‰nh liÃªn tiáº¿p (tÃ­nh báº±ng sá»‘ máº«u)
    rr_intervals = np.diff(peaks)
    rr_ms = (rr_intervals / fs) * 1000
    
    # 2. TÃ­nh cÃ¡c chá»‰ sá»‘ HRV (Time-domain)
    # SDNN: Äá»™ lá»‡ch chuáº©n cá»§a cÃ¡c khoáº£ng RR (ÄÃ¡nh giÃ¡ sá»©c khá»e tá»•ng quÃ¡t)
    sdnn = np.std(rr_ms)
    
    # RMSSD: CÄƒn báº­c hai cá»§a trung bÃ¬nh bÃ¬nh phÆ°Æ¡ng sá»± khÃ¡c biá»‡t giá»¯a cÃ¡c khoáº£ng RR liÃªn tiáº¿p
    # (ÄÃ¡nh giÃ¡ hoáº¡t Ä‘á»™ng cá»§a há»‡ tháº§n kinh phÃ³ giao cáº£m)
    diff_rr = np.diff(rr_ms)
    rmssd = np.sqrt(np.mean(diff_rr**2))
    
    # Nhá»‹p tim trung bÃ¬nh (BPM)
    mean_rr = np.mean(rr_ms)
    mean_bpm = 60000 / mean_rr
    
    # 3. Chuáº©n bá»‹ dá»¯ liá»‡u PoincarÃ© Plot
    # Trá»¥c X: RR[n], Trá»¥c Y: RR[n+1]
    poincare_x = rr_ms[:-1]
    poincare_y = rr_ms[1:]
    
    return {
        "rr_ms": rr_ms,
        "sdnn": sdnn,
        "rmssd": rmssd,
        "mean_bpm": mean_bpm,
        "poincare_x": poincare_x,
        "poincare_y": poincare_y
    }

def analyze_batch_data(patient_data_map, model, fs=360, wavelet='sym8', r_peak_height=0.5):
    """
    Cháº¡y phÃ¢n tÃ­ch hÃ ng loáº¡t trÃªn toÃ n bá»™ dataset.
    Tráº£ vá» DataFrame tÃ³m táº¯t Ä‘á»ƒ hiá»ƒn thá»‹ báº£ng.
    """
    results = []
    
    # Láº¥y Ä‘á»™ dÃ i input cáº§n thiáº¿t
    required_len = get_model_input_length(model)
    
    # Duyá»‡t qua tá»«ng bá»‡nh nhÃ¢n/báº£n ghi
    # Sá»­ dá»¥ng enumerate Ä‘á»ƒ tráº£ vá» tiáº¿n trÃ¬nh náº¿u cáº§n
    total_files = len(patient_data_map)
    
    for idx, (pid, raw_signal) in enumerate(patient_data_map.items()):
        try:
            # 1. Chuyá»ƒn Ä‘á»•i sang numpy array
            signal = np.array(raw_signal)
            
            # 2. Xá»­ lÃ½ tÃ­n hiá»‡u
            denoised = denoise_signal_wavelet(signal, wavelet=wavelet)
            segments, peaks = detect_and_segment(denoised, r_peak_height, output_length=required_len)
            
            stats = {
                "ID": pid,
                "Total Beats": 0,
                "BPM (Avg)": 0,
                "Status": "Error",
                "Risk Level": "Unknown",
                "N": 0, "S": 0, "V": 0, "F": 0, "Q": 0
            }

            if len(segments) > 0:
                # 3. Dá»± Ä‘oÃ¡n
                pred_codes, _ = predict_from_segments(segments, model)
                
                # 4. Thá»‘ng kÃª
                counts = pd.Series(pred_codes).value_counts()
                total_beats = len(pred_codes)
                
                # TÃ­nh nhá»‹p tim trung bÃ¬nh
                if len(peaks) > 1:
                    avg_diff = np.mean(np.diff(peaks))
                    bpm = int(60 / (avg_diff / fs))
                else:
                    bpm = 0
                
                # Cáº­p nháº­t stats
                stats["Total Beats"] = total_beats
                stats["BPM (Avg)"] = bpm
                stats["Status"] = "Success"
                
                # Fill sá»‘ lÆ°á»£ng tá»«ng loáº¡i
                for code in ['N', 'S', 'V', 'F', 'Q']:
                    count = counts.get(code, 0)
                    stats[code] = count
                
                # ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ nguy hiá»ƒm
                if stats['V'] > 0 or stats['F'] > 0:
                    stats['Risk Level'] = "High ğŸ”´"
                elif stats['S'] > 0:
                    stats['Risk Level'] = "Medium ğŸŸ¡"
                else:
                    stats['Risk Level'] = "Low ğŸŸ¢"
            else:
                stats["Status"] = "No Peaks Found"
                
            results.append(stats)
            
        except Exception as e:
            results.append({"ID": pid, "Status": f"Error: {str(e)}", "Risk Level": "Error"})

    return pd.DataFrame(results)