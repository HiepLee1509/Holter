# .\venv\Scripts\activate
# streamlit run app.py
import streamlit as st
import pandas as pd
import numpy as np
import os
import json
import ast

from src.backend import load_arrhythmia_model, get_model_input_length
from src.ui_config import setup_page_config, apply_custom_css
from src.view_single import render_single_analysis
from src.view_batch import render_batch_analysis

# 1. Cáº¤U HÃŒNH TRANG & GIAO DIá»†N
setup_page_config()
apply_custom_css()

# --- Táº¢I MODEL ---
@st.cache_resource
def setup_model(model_path):
    if not os.path.exists(model_path):
        return None, 0
    model = load_arrhythmia_model(model_path)
    input_len = get_model_input_length(model)
    return model, input_len

MODEL_PATH = "model\\ecg_model_code 17_t5.h5"
model, REQUIRED_LENGTH = setup_model(MODEL_PATH)

# SIDEBAR (INPUT & SETTINGS)
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2966/2966486.png", width=80)
    st.title("AI Heart Guard")
    st.markdown("---")
    
    st.header("1. Nháº­p Dá»¯ Liá»‡u")
    uploaded_file = st.file_uploader("Upload JSON/CSV", type=["json", "csv"])
    
    st.header("2. Tham sá»‘ Ká»¹ thuáº­t")
    fs = st.number_input("Táº§n sá»‘ láº¥y máº«u (Hz)", 100, 1000, 360, help="MIT-BIH thÆ°á»ng lÃ  360Hz")
    
    with st.expander("NÃ¢ng cao (Wavelet/Peak)"):
        wavelet_type = st.selectbox("Wavelet Type", ['sym8', 'db4', 'db8'], index=0)
        r_peak_height = st.slider("Min Peak Height", 0.1, 5.0, 0.5)
    
    st.markdown("---")
    st.caption("Developed by LÃª NghÄ©a Hiá»‡p\nMSSV: 20235326")

# MAIN CONTENT
st.title("ğŸ«€ PhÃ¢n tÃ­ch & Cháº©n Ä‘oÃ¡n Rá»‘i loáº¡n nhá»‹p tim ECG")
st.markdown("Há»‡ thá»‘ng há»— trá»£ cháº©n Ä‘oÃ¡n tá»± Ä‘á»™ng sá»­ dá»¥ng mÃ´ hÃ¬nh AI **Deep Learning (CNN + LSTM)**.")

# Model Checking
if model is None:
    st.error(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file model táº¡i `{MODEL_PATH}`. Vui lÃ²ng kiá»ƒm tra láº¡i thÆ° má»¥c dá»± Ã¡n.")
    st.stop()

# Controller Logic
patient_data_map = {}

if uploaded_file is not None:
    try:
        # Read JSON/CSV file
        if uploaded_file.name.endswith('.json'):
            data = json.load(uploaded_file)
            if isinstance(data, list):
                for i, d in enumerate(data):
                    patient_data_map[d.get("id", f"Rec {i}")] = d["reading"]
            elif isinstance(data, dict):
                patient_data_map = data
        elif uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
            if 'reading' in df.columns:
                 for i, row in df.iterrows():
                    val = row['reading']
                    reading = ast.literal_eval(val) if isinstance(val, str) else val
                    patient_data_map[str(row.get('id', f"Row {i}"))] = reading
            else:
                 for i in range(len(df)):
                    reading = df.iloc[i].values.tolist()
                    if len(reading)>100: patient_data_map[f"Row {i}"] = reading
    except Exception as e:
        st.error(f"Lá»—i Ä‘á»c file: {e}")
        
# ROUTING TO VIEWS
if patient_data_map:
    st.success(f"âœ… ÄÃ£ táº£i thÃ nh cÃ´ng dá»¯ liá»‡u {len(patient_data_map)} id cá»§a bá»‡nh nhÃ¢n.")
    
    # Create Tabs for Single and Batch Analysis
    tab_single, tab_batch = st.tabs(["ğŸ‘¤ PhÃ¢n tÃ­ch trÃªn 1 id cá»¥ thá»ƒ (Single mode)", "ğŸ‘¥ QuÃ©t toÃ n bá»™ (Scan mode)"])

    with tab_single:
        # Call View Single
        render_single_analysis(
            patient_data_map, 
            model, 
            fs, 
            wavelet_type, 
            r_peak_height, 
            REQUIRED_LENGTH
        )

    with tab_batch:
        # Call View Batch
        render_batch_analysis(
            patient_data_map, 
            model, 
            fs, 
            wavelet_type, 
            r_peak_height
        )

else:
    st.info("ğŸ‘ˆ Vui lÃ²ng táº£i lÃªn file dá»¯ liá»‡u (JSON hoáº·c CSV) á»Ÿ thanh bÃªn trÃ¡i Ä‘á»ƒ báº¯t Ä‘áº§u.")